![team title ](https://github.com/user-attachments/assets/b2494fc4-9853-4cbc-a798-b7571da98a59) 


## Authors
- [Ann Gray Perdue](https://github.com/agp03)
- [Helen Nguyen](https://github.com/nguyenyhelen)
- [Kia Morawetz](https://github.com/kiamorawetz)
- [Rakshya Khadka](https://github.com/jililyx)

## Project Scope
![claude and gemini logo](https://github.com/user-attachments/assets/572b4929-eebd-4455-bea9-192652ba5222)

Responsible AI. Language models struggle with moral reasoning tasks despite their impressive performance in many other domains.


## Project Details

Exploring different ways on how AI and Ethics come hand in hand. 

![copilot and chat logo ](https://github.com/user-attachments/assets/b1d512bd-42f6-45b5-9a85-dfb58cc8a335)

## Website 
[Ethical Decision Explorer](https://script.google.com/a/macros/wm.edu/s/AKfycbwa2BjP9QteXyv0JI0Uiz1qYVeD89bw1dD41F2lk-SseQxV_phRufW26gkRR2df_RG4wQ/exec)

## What's Next?
Understanding how to tackle AI Dilemmas and and the decisions that AI makes. 
A new prompting framework called "Thought Experiments" uses counterfactual thinking to encourage more comprehensive moral reasoning.

## Responsible AI Summary 

## References 
[Let's Do a Thought Experiment: Using Counterfactuals to Improve Moral Reasoning](https://research.google/pubs/lets-do-a-thought-experiment-using-counterfactuals-to-improve-moral-reasoning/)


![team title](https://github.com/user-attachments/assets/b2494fc4-9853-4cbc-a798-b7571da98a59)

## Authors
- [Ann Gray Perdue](https://github.com/agp03)
- [Helen Nguyen](https://github.com/nguyenyhelen)
- [Kia Morawetz](https://github.com/kiamorawetz)
- [Rakshya Khadka](https://github.com/jililyx)

---

## Project Scope  
![claude and gemini logo](https://github.com/user-attachments/assets/572b4929-eebd-4455-bea9-192652ba5222)

As large language models (LLMs) become increasingly integrated into decision-making systems, they must be equipped to reason through complex, value-laden situations. Yet, current models underperform on **moral reasoning tasks**, such as those in the MMLU benchmark. This project explores how *responsible AI* can be improved by aligning model behavior with **ethical principles**.

---

## Project Details  
Exploring how **AI and ethics intersect**, we created an interactive platform that allows users to engage with difficult moral dilemmas and see how different choices unfold across ethical perspectives.

Our tool builds on the **Thought Experiments** prompting framework (Ma et al., 2023), which improves model reasoning by incorporating *counterfactual thinking*â€”asking "what if?" to evaluate outcomes, duties, and values.

![copilot and chat logo](https://github.com/user-attachments/assets/b1d512bd-42f6-45b5-9a85-dfb58cc8a335)

---

## Website  
ðŸ”— [Ethical Decision Explorer](https://script.google.com/a/macros/wm.edu/s/AKfycbwa2BjP9QteXyv0JI0Uiz1qYVeD89bw1dD41F2lk-SseQxV_phRufW26gkRR2df_RG4wQ/exec)

Users can:
- Navigate through ethical scenarios
- Choose between conflicting actions
- View detailed analyses through four major ethical frameworks:
  
  - **Utilitarianism**
  - **Deontology**
  - **Virtue Ethics**
  - **Care Ethics**

---

## Website Prompt: Ethical Decision Explorer

### Concept & Interactivity
- A web-based tool that presents users with **moral dilemmas** inspired by **Moral Scenarios** research.
- Users are shown a **scenario** with **multiple-choice actions**.
- After a choice is made, **GenAI**:
  - Generates possible outcomes.
  - Highlights ethical implications.
  - Simulates "what if" counterfactuals.
- Users can:
  - **Explore different decision paths**.
  - **Compare ethical consequences** of each action.

> ðŸ’¡ *Built using Google Apps Script and GenAI integration.*
  
---

## What's Next?  
Understanding how LLMs can:
- Make more **transparent and justifiable decisions**
- Handle **ethical dilemmas** with nuance
- Respect both individual agency and societal good  

We continue refining prompts and training workflows to support AI agents that **reason more like humans**, especially when moral complexity is involved.

A next step is expanding the scenario set and testing the Thought Experiments method on **open-ended generation tasks** beyond multiple choice.

---

![ethical image](https://github.com/user-attachments/assets/22600356-47d3-48a6-a6ca-dcefea4ed555)

## Responsible AI Summary  

This project contributes to **responsible AI development** by:

- Encouraging **ethical transparency** in model decisions  
- Introducing a **multi-framework evaluation** to explore moral nuance  
- Demonstrating how counterfactual reasoning improves performance on moral judgment tasks  
- Highlighting limitations of binary ethics and the need for **context-aware reasoning** in AI

## Project Updates

[Kanban](https://github.com/users/jililyx/projects/6)


## References  
- [Letâ€™s Do a Thought Experiment: Using Counterfactuals to Improve Moral Reasoning (Ma et al., 2023)](https://research.google/pubs/lets-do-a-thought-experiment-using-counterfactuals-to-improve-moral-reasoning/)  


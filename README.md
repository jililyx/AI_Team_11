

## Authors
- [Ann Gray Perdue](https://github.com/agp03)
- [Helen Nguyen](https://github.com/nguyenyhelen)
- [Kia Morawetz](https://github.com/kiamorawetz)
- [Rakshya Khadka](https://github.com/jililyx)

## Project Scope
Responsible AI. Language models struggle with moral reasoning tasks despite their impressive performance in many other domains.


## Project Details
Exploring different ways on how AI and Ethics come hand in hand. 

## Website 
[Ethical Decision Explorer](https://script.google.com/a/macros/wm.edu/s/AKfycbwa2BjP9QteXyv0JI0Uiz1qYVeD89bw1dD41F2lk-SseQxV_phRufW26gkRR2df_RG4wQ/exec)

## What's Next?
Understanding how to tackle AI Dilemmas and and the decisions that AI makes. 
A new prompting framework called "Thought Experiments" uses counterfactual thinking to encourage more comprehensive moral reasoning.

## Responsible AI Summary 

## References 
[Let's Do a Thought Experiment: Using Counterfactuals to Improve Moral Reasoning](https://research.google/pubs/lets-do-a-thought-experiment-using-counterfactuals-to-improve-moral-reasoning/)

